# Module 3 Reflection – Code Quality & Review

After completing the labs and quiz, use this template to reflect on your experience.  Honest and thoughtful reflections will help you and your team improve your AI‑assisted development workflow.

1. **Summary of tasks:** Briefly describe the functions, features or refactorings you worked on in Labs 1–3.  Include which files you modified and which static/security tools you used.

2. **Vulnerabilities and issues discovered:** List the most significant bugs, vulnerabilities or style issues you found during the labs.  Indicate whether they were detected by static analysis, security scanning or manual review.  Explain why they were problematic.

3. **Fixes and improvements:** For each issue identified, describe how you fixed it.  Did you modify your AI prompt, refactor the code manually, change dependencies or update configuration?  Share any helpful resources or patterns you used.

4. **Prompt engineering:** Provide examples of prompts you used to guide Copilot or Roo Code.  What wording produced the best results?  Did you iterate on the prompts after seeing static analysis or review feedback?

5. **Review process:** Reflect on the review workflow.  How did combining static analysis, manual peer review and security scanning improve your confidence in the code?  What challenges did you encounter when reconciling AI suggestions with reviewer feedback?

6. **Lessons learned:** Summarise the key takeaways from Module 3.  What best practices will you apply to future AI‑assisted projects?  How will you encourage your team to adopt these practices?

Use this reflection as a personal record and share it with your trainer or team lead.  Your insights will help improve the adoption of AI tools while maintaining high standards for quality and security.